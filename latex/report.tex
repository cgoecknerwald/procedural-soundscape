\documentclass[12pt,a4paper]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% File directory tree
\usepackage{dirtree}
% Verbatim code / psuedocode styling
\usepackage{etoolbox}
% Graphic (images) styling
\usepackage{graphicx}
% For URL hyperlinks (including in references.bib)
\usepackage{hyperref}
% For musical notation
\usepackage{harmony}
% BibTex styling
\usepackage{natbib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% For monospacing (for package names, variable names, etc.)
\newcommand{\code}{\texttt}

% Better inline directory listings (slightly gray)
\usepackage{xcolor}
\definecolor{light-gray}{gray}{0.95}
\newcommand{\lightcode}[1]{\colorbox{light-gray}{\texttt{#1}}}

% Custom command so we write 4-4 time.
\newcommand{\setmeter}[2]{\ensuremath{%
  \vcenter{\offinterlineskip
    \halign{\hfil##\hfil\cr
            $\scriptstyle#1$\cr
            \noalign{\vskip1pt}
            $\scriptstyle#2$\cr}
  }}%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Page dimensions %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  DO NOT CHANGE  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textheight=247mm
\textwidth=160mm
\topmargin=-7mm
\oddsidemargin=-2mm
\evensidemargin=-8mm
\parindent 10pt

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Start of document %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\pagestyle{plain}
\pagenumbering{arabic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Title of proposal %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\LARGE{\bf
%%
%% TITLE
{{Procedural Soundscape}}
%%
%%
}}
\end{center}
\bigskip

%% Principal Investigator (PI) initial(s) and family name %%
\centerline{\bf{Claire Goeckner-Wald \& Amy Xiong}}

\bigskip

% Type a concise abstract of your proposal here (optional).
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Executive Summary}

We built a website with a procedural-generated soundscape inspired by `\href{https://www.youtube.com/watch?v=K2Q6YO3Ez44}{coffeehouse jazz}'. While we did not integrate the soundscape with live variables, we did integrate it with a synesthetic background image. It would not be terribly difficult to integrate the soundscape with live variables at this point, but we chose not to due to time constraints. The music consists of a single melody line, played by a saxophone, and an underlying bass line, played by a electric bass. We generate music measure by measure, choosing notes and rhythms randomly from a preset selection (for notes, the preset is a randomly-chosen scale, and for rhythms, a set of 8 rhythms, which then may be lengthened or shortened). To make it sound more musical, we limit the intervals between consecutive notes, and include rests, repeats, and runs. The music can be paused, played, or restarted with new parameters. We chose to use \lightcode{tonejs-instruments} because it integrated open-source \code{WAV}-format files from real instruments with \lightcode{Tone.js} \cite{tonejs-instruments}. We tested the final product in both the latest version of \href{https://www.mozilla.org/en-US/firefox/}{Mozilla Firefox} (Mozilla Firefox Quantum 63.0) and \href{https://www.google.com/chrome/index.html}{Google Chrome} (Google Chrome 70.0). Rather than using \href{https://cloud.google.com/appengine/}{Google App Engine}, or similar, we simply hosted the website for free on Claire's personal GitHub site, \href{https://cgoecknerwald.github.io/procedural-soundscape}{cgoecknerwald.github.io/procedural-soundscape}. This greatly simplified the workflow, as we could easily push HTML/CS/JS to the GitHub repository, and it would then be immediately updated online with no extra work.

\subsection{Description}

The entire codebase (and the original \code{LaTeX} files for this very report) can be found on Claire's GitHub repository: \href{https://github.com/cgoecknerwald/procedural-soundscape}{github.com/cgoecknerwald/procedural-soundscape}. The web application is live at \href{https://cgoecknerwald.github.io/procedural-soundscape/}{cgoecknerwald.github.io/procedural-soundscape/}.

\begin{itemize}
	\item A web application
	\item A procedural soundscape
	\item A visual landscape
\end{itemize}

\subsection{Technical Requirements}
\begin{itemize}
	\item Browser: Firefox Quantum 63.0 and above, or Google Chrome 70.0 and above.
	\item User input: Interaction with web browser via cursor.
	\item User output: Any functioning speakers will do.
\end{itemize}

Since Firefox and Chrome use unique browser engines -- Gecko and Blink, respectively -- we reasoned that this would be sufficient coverage. Brief trials with Safari, which uses WebKit, have been successful, as well. We did not test at all on Internet Explorer.

\subsection{Technical Challenges}
We had issues with \lightcode{Tone.js}, namely with building realistic synths. Splitting our code into multiple files and including the recorded instrument files gave us CORS permission issues, for local testing. We ended up finding a workaround for Firefox, but not for Chrome, so we had to switch to Firefox for local testing.

\subsection{Licensing}
We chose to license our repository with the MIT License.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Technical Design}

\subsection{Sound Design Tool Discussion}
We've decided to use \lightcode{Tone.js} instead of \lightcode{Audiosynth.js} by Keith William Horwood. We also chose \lightcode{Tone.js} over \lightcode{SuperCollider}, \lightcode{Flocking.js}, \lightcode{PureData}, because of web integration ease. \lightcode{Flocking.js} also had web integration but a smaller online community and seemed less robust and less abstracted. \lightcode{Audiosynth.js} did not have looping technologies. We briefly considered integrating our whole product with \lightcode{Audiosynth.js} but it proved to be too difficult.

\subsubsection{PureData}
One of \lightcode{PureData}'s strong points seems to be its easy and intuitive low-level sound synthesis, but we were more interested in higher-level procedural music generation than detailed sound creation. In general, \lightcode{PureData} was far too low-level (and therefore tedious and slow) for our plans. We also weren't quite sure how we'd integrate into a web application.

\begin{quote}
Pure Data is an open source visual programming environment that runs on anything from personal computers to embedded devices (ie Raspberry Pi) and smartphones (via libpd, DroidParty (Android), and PdParty (iOS). It is a major branch of the family of patcher programming languages known as Max (Max/FTS, ISPW Max, Max/MSP, etc), originally developed by Miller Puckette at IRCAM.

Pd enables musicians, visual artists, performers, researchers, and developers to create software graphically without writing lines of code. Pd can be used to process and generate sound, video, 2D/3D graphics, and interface sensors, input devices, and MIDI. Pd can easily work over local and remote networks to integrate wearable technology, motor systems, lighting rigs, and other equipment. It is suitable for learning basic multimedia processing and visual programming methods as well as for realizing complex systems for large-scale projects.

Algorithmic functions are represented in Pd by visual boxes called objects placed within a patching window called a canvas. Data flow between objects are achieved through visual connections called patch cords. Each object performs a specific task, which can vary in complexity from very low-level mathematical operations to complicated audio or video functions such as reverberation, FFT transformations, or video decoding. Objects include core Pd vanilla objects, external objects or externals (Pd objects compiled from C or C++), and abstractions (Pd patches loaded as objects). \cite{puredata}
\end{quote}

\subsubsection{SuperCollider}
\lightcode{SuperCollider} seemed okay at first, but we could not see an easy way to integrate it with HTML/JS/CSS (knowing that we wanted to build a web application). And similar to \lightcode{PureData}, \lightcode{SuperCollider} seemed a bit too low-level for our plans. In particular, our project was unlikely to take advantage of the extensive sound synthesis tools that it provided.

\begin{quote}
SuperCollider is a platform for audio synthesis and algorithmic composition, used by musicians, artists, and researchers working with sound. It is free and open source software available for Windows, macOS, and Linux. \cite{supercollider}
\end{quote}

\subsubsection{Flocking.js}
\lightcode{Flocking.js} was a strong contender for our choice of sound design technology. However, it was very difficult to find examples of projects using \lightcode{Flocking.js}. The documentation and other support resources were also a little lacking.

\begin{quote}
Flocking is a JavaScript audio synthesis framework designed for artists and musicians who are building creative and experimental Web-based sound projects. It runs in Firefox, Chrome, Safari, Edge, and Node.js on Mac OS X, Windows, Linux, iOS, and Android.

Flocking is different. Its goal is to promote a uniquely community-minded approach to instrument design and composition. In Flocking, unit generators and synths are specified declaratively as JSON, making it easy to save, share, and manipulate your synthesis algorithms. Send your synths via Ajax, save them for later using HTML5 local data storage, or algorithmically produce new instruments on the fly.

Because it's just JSON, every instrument you build using Flocking can be easily modified and extended by others without forcing them to fork or cut and paste your code. This declarative approach will also help make it easier to create new authoring, performance, metaprogramming, and social tools on top of Flocking.

Flocking was inspired by the SuperCollider desktop synthesis environment. If you're familiar with SuperCollider, you'll feel at home with Flocking. \cite{flocking}
\end{quote}

\subsubsection{Audiosynth.js}

Partway through the project, we stumbled upon \lightcode{Audiosynth.js}, and briefly considered switching to it. One of the main draws was that it had several instruments built into it already. However, we found \lightcode{Audiosynth.js} to be a lot less fully-featured than \lightcode{Tone.js}. In particular, \lightcode{Audiosynth.js} did not have the sophisticated scheduling system that \lightcode{Tone.js} did, meaning that we'd have to handle all the low-level details of music timing ourselves. We ultimately decided that this would require too much work, and opted to stick with \lightcode{Tone.js}.

\begin{quote}
Dynamic waveform audio synthesizer, written in Javascript. Generate musical notes dynamically and play them in your browser using the HTML5 Audio Element. No static files required. (Besides the source, of course!) \cite{audiosynth}
\end{quote}


\subsubsection{Tone.js}
In the end, we chose \lightcode{Tone.js} out of all three Javascript sound design frameworks for its robust online community (and therefore support). We were able to find many examples of very cool musical projects others had done using \lightcode{Tone.js}, and there was also quite extensive documentation for it. \lightcode{Tone.js} also provided a very sophisticated scheduling system that made music generation much simpler.

\begin{quote}
Tone.js is a Web Audio framework for creating interactive music in the browser. The architecture of Tone.js aims to be familiar to both musicians and audio programmers looking to create web-based audio applications. On the high-level, Tone offers common DAW (digital audio workstation) features like a global transport for scheduling events and prebuilt synths and effects. For signal-processing programmers (coming from languages like Max/MSP), Tone provides a wealth of high performance, low latency building blocks and DSP modules to build your own synthesizers, effects, and complex control signals. \cite{tonejs}
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Technological Review}

We looked at Karplus-Strong String Synthesis but determined it was only relevant if we used \lightcode{Audiosynth.js} \cite{karplus-strong}.

\subsubsection{Tambien's Tone.js}
For the reasons discussed in `2. Sound Design Tool Discussion' above, we ultimately chose \lightcode{Tone.js} as our main sound design package.

\subsubsection{Nbrosowsky's tonejs-instruments}
The package \lightcode{tonejs-instruments} was instrumental (haha) in our final project. It features soundclips for many instruments, such as piano, clarinet, guitar, violin, etc., all in \code{WAV}, \code{MP3}, and \code{OGG} formats. It allowed us to move away from a very ``synth-y" sound to real soundclips from instruments. We ended up using a saxophone for our melody instrument and an electric bass for our bass line.

\subsubsection{Wheelibin's synaesthesia}
Synaesthesia is a web application that randomly produces music based off of an input string. Its method of generating music with multiple instrument lines (including drum kit), incorporating scales and chord progressions, was really useful examples for us to investigate. We modified his drum kit and synths. We also based our \code{assets/js/chords.js} and \code{assets/js/rhythms.js} off of \lightcode{synaesthesia}.

\subsubsection{Tambien's jazz.computer}
We got mostly drums synths and pads from \code{tambien} (Yotam Mann, creator of \lightcode{Tone.js})'s \href{http://jazz.computer/}{\lightcode{jazz.computer}} (works best in Chrome or Safari). \code{Tambien}'s \href{http://jazz.computer/}{\lightcode{jazz.computer}} but they had a very strange music set-up with interpolation and mediators between synths. We attempted to replicate by playing mulitple synths simulataneously but the resulting 'piano' was very tinny and sounded like Scottish bagpipes.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Musical Review}

\subsubsection{Scheduling}
The first challenge was in getting \lightcode{Tone.js} to produce random music that would play forever. \lightcode{Tone.js}'s has a nice scheduling system for producing music, with scheduling components that allowed you to play a series of notes in a row (e.g. \href{https://tonejs.github.io/docs/r12/Part}{\lightcode{Tone.Part}}).

However, \lightcode{Tone.js} can only repeat in regular intervals. It could not, for example, calculate the amount of time a section of music would take, then automatically repeat after that section was finished. This meant we had to make each randomly-generated section of music be of the same length, in order for them to fit together without breaks in the music. We thus decided to generate music one full measure at a time.

\lightcode{Tone.js} also allows you to have multiple notes playing at the same time. As such, you must specify both the duration of the note and when it should be played, not just one or the other. We had to thus separately track the time elapsed as we randomly generated our notes, in order to be able to know when to schedule the next note.

\subsubsection{Rhythm}

For random rhythm patterns, we used a set of 8 rhythms patterns \cite{common-rhythms}:

% if we can use package harmony, commands are in comments
\begin{center}
\begin{tabular}{ l r }
whole & \Ganz \\
half half & \Halb \Halb \\
dotted-half quarter & \Halb\Pu \Vier \\
quarter dotted-half & \Vier \Halb\Pu \\
half quarter quarter & \Halb \Vier \Vier \\
quarter half quarter & \Vier \Halb \Vier \\
quarter quarter half & \Vier \Vier \Halb \\
quarter quarter quarter quarter & \Vier \Vier \Vier \Vier \\
\end{tabular}
\end{center}

All rhythm constants are stored in \code{assets/js/rhythms.js}.

Note that each of these rhythms take up exactly one measure (in \setmeter{4}{4} time).
We then augmented this set by using the same patterns with shorter notes. We halved all the note lengths to get an equivalent set of rhythm patterns that take up half a measure, and then halved the lengths again to get another set that take up one quarter note.

We generate music one measure at a time, but within each measure, we generate the measure by connecting together these rhythm patterns. Since some of the patterns are shorter than a measure (the length of either one quarter note or one half note), we must be sure to generate the appropriate number of rhythm-segments, of the appropriate length, to exactly equal one measure of music.

For example, we might generate a measure of music by first generating four sixteenth-notes (a one-quarter-note rhythm pattern), then one half-note (a one-half-note rhythm pattern), then finally two eighth-notes (a one-quarter-note rhythm pattern again). We cannot, however, generate first four sixteenth-notes, then four quarter-notes, as that will last longer than one measure. We also cannot generate four sixteenth-notes, then one half-note, then stop, since that will last shorter than one measure.

\lightcode{createMeasure} handles creating an individual measure. The function randomly decides what length of music to generate (1, 2, or 4 quarter notes of music) that falls within the time remaining in the measure, until it's filled up the entire measure. It then calls \lightcode{createSectionNotes} (which calls \lightcode{generateNotes}) with the specified length. These functions randomly pick one of the 8 possible rhythms (and they also handle pitch generation, runs, and repeats, described in later sections). The shorter rhythms (half-note-length or quarter-note-length) are obtained by dividing the note lengths according to whether it's generating 1, 2, or 4 quarter notes of music.

The bass line is much simpler. It has a set of four possible rhythms: 1. one note every beat, 2. one note on the first beat of the measure, 3. one note on the first and third beats, and 4. one note on the second and fourth beats. At the start of the music, one of these rhythms is randomly chosen and repeated every measure.

\subsubsection{Pitch Generation}

Pitches are also randomly generated. When the website is first loaded, it randomly picks a tonic note and a scale type to build a scale (e.g. C Major, A-flat Minor, D-sharp Dorian). Note pitches are chosen only from this scale.

The bass line plays only the tonic of the scale. The melody line (possibly) changes pitch for every new note. Since in real music, the difference in pitch from one note to the next is usually just a small interval, our program randomly chooses a new pitch that is within three notes (in the scale) from the previous pitch. For example, if the scale is D major, the melody might move from D to G to F-sharp to E to E again. The melody could move from D to the A below, but never to the A above.

To actually choose the next note, we start from a variable, \lightcode{currPitchIndex}, which records the index into the array of available notes for the current note. We then generate an array of the indices of all the possible next notes, in the distribution specified by our constant array of intervals. An index is randomly chosen from this array of possibilities, the index is used to obtain the next pitch, and \lightcode{currPitchIndex} is updated to this index, to be used for the next note.

It's also common in music for there to exist a ``run" of notes. By a ``run", we mean a series of ascending or descending notes that follow the scale. Some examples would be G-A-B-C in C major, A-flat-G-F in F minor, etc. Thus, every time a new rhythm-and-note-pattern is generated, there's a random chance for the melody to start a run of notes. While in a run, the interval from one note to the next is no longer randomized, and is instead always fixed at 1 (for ascending runs) or -1 (for descending runs). While in a run, every time a new rhythm-and-note-pattern is generated, there is also a random chance to stop the run.

We specified octave ranges for the pitch, as well. For the saxophone recordings, we found that only octaves 2 through 4 sounded good, and so all the melody pitches are restricted to these three octaves. If a run tries to go outside the octave bounds, we stop the run. Our original system for choosing the next note was to first randomly chose an interval, then calculate the pitch from \lightcode{currPitchIndex} and that interval. One of the motivations behind switching to the current approach (first generate all possible pitches from all possible intervals, then randomly choose a pitch) is that it handled staying within the octave range better. With the previous approach, we would simply re-generate the note until it fell within the correct octave range. This, however, is inefficient, and actually has the theoretical possibility of looping forever.

\subsubsection{Repeats}

Music contains a lot of repetition\textemdash in whole measures or phrases, in single notes, in melodic lines and rhythms. To increase the musicality of our music generator, we added some very simple repetition.

Every time a new rhythm pattern is generated, there is a fixed chance that that rhythm pattern might be exactly repeated. If there isn't enough room in the measure to repeat the pattern (i.e. if repeating the pattern would extend past the end of the measure), then the pattern won't be repeated. In addition, every individual measure also has a fixed chance of repeating.

\subsubsection{Randomness}

All the randomness is produced by using \lightcode{Math.random()}.

A series of constants control much of the randomness. These constants govern the chance the next note (while not in a run) will be higher than the previous note (set to 0.5), the chance to start a run (0.5), the chance to end the run (0.7), the chance the run will be an ascending run (0.5), the chance to repeat the previous rhythm-and-note pattern (0.3), the chance to repeat an entire measure (0.2), and the chance to have a rest instead of a note (0.3). Since these are constants, it's very easy for us to quickly change them, which then alters the character of the melody.

For the rest of the randomness, all the options have equal chance. These include choosing one of the 8 rhythms for the melody, choosing the bass line rhythm, choosing which scale type and tonic to use, and choosing whether to generate 1, 2, or 4 quarter notes of music.

The one exception is the intervals between notes in the melody (while not in a run). For this, our code randomly chooses an integer out of a constant array, and this integer determines the magnitude of the interval between the current note and the next note. Each element in the array has an equal chance of being chosen, but some numbers are duplicated, to give a distribution of intervals that we thought would sound best. The array: \lightcode{[0, 0, 1, 1, 1, 2, 2, 3]}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{User Interface}
We wanted to make our user interface fun without being confusing, or being so difficult to implement that it distracts from the work of sound design. We settled on a semi-transparent paneling design that would allow us to compartmentalize the different functions while showing off a collection of highly-textured backgrounds.

\begin{figure}
\centering\includegraphics[width=0.8\textwidth]{images/loading.png}
\caption{The loading screen as seen on Firefox Quantum 63.0. During this screen, fonts, and \code{WAV} soundfiles are loading.}
\end{figure}

\begin{figure}
\centering\includegraphics[width=0.8\textwidth]{images/loaded.png}
\caption{The pre-interaction screen as seen on Firefox Quantum 63.0. This screen occurs after loading is finished, but before the user has interacted with the interface. To begin, users can interact with the play/pause button and the reload/refresh button.}
\end{figure}

\begin{figure}
\centering\includegraphics[width=0.8\textwidth]{images/ui.png}
\caption{The post-interaction user interface as seen on Firefox Quantum 63.0. Users can interact with the play/pause button and the reload/refresh button.}
\end{figure}

\subsubsection{Actions}

There are two actions a user make take: toggle play-pause button or toggle refresh button. Toggling the play-pause button functions exactly as expected - if the music is playing, it stops the music. If the music is not playing, it restarts the music exactly where it left off (or, at the beginning, if toggled for the first time). Toggling the refresh button updates the background, BPM, and key. It necessarily restarts the music, as well.

The first time that either the play-pause button or refresh button is toggled, the program initializes a background, BPM, and key. These three qualities are \textit{unlinked}, meaning they change independently of each other. We considered using a \lightcode{constants.json} file to build dependencies between the backgrounds and the type of music. However, given the large variety of backgrounds we wished to use, we found that this functionality would be cumbersome without adding significant value to the project.

The program also features a count-down because we generate notes a full measure in advance (so that we may display them on screen). Without this extrapolative generation, we may encounter an issue with \lightcode{Tone.js} where the first note is not scheduled in advance of being played, causing the first note to be `dropped,' or not played at all.

\subsubsection{Displays}

There are 3 different kinds of dynamic information displays to the user: the notes, the BPM, and the key.

The notes are scheduled a full measure in advance, which allows us to display them on screen. The function \code{emphasizeNote()} uses the index of the currently sounded note to updated the displayed HTML. In this way, the user can visually track the notes (or rests!) as they are sent live to \lightcode{Tone.js}.


\subsubsection{Backgrounds}

The project features approximately 50 unique backgrounds (the number fluctuates when we delete one we don't like). The backgrounds were selected for their flat, textured appeal from \href{https://unsplash.com/about}{Unsplash} \cite{unsplash}. Unsplash was used for its selection of ``Over 550,000 free (\href{https://unsplash.com/license}{do-whatever-you-want}) high-resolution photos brought to you by the world’s most generous community of photographers,'' with a very generous \href{https://unsplash.com/license}{license}.

\begin{figure}
\centering\includegraphics[width=0.48\textwidth]{images/bg1.png}
\centering\includegraphics[width=0.48\textwidth]{images/bg2.png}
\centering\includegraphics[width=0.48\textwidth]{images/bg3.png}
\centering\includegraphics[width=0.48\textwidth]{images/bg4.png}
\caption{Various backgrounds.}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Must use \clearpage instead of \newpage or \pagebreak, to clear figure environs
\clearpage
\subsection{File Directory Structure}

\dirtree{%
.1 procedural-soundscape.
.2 assets.
.3 backgrounds.
.4 bg0.jpg.
.4 bg1.jpg.
.4 \dots.
.4 bgN.jpg.
.3 css.
.4 main.css.
.3 js.
.4 chords.js.
.4 constants.json.
.4 instruments.js.
.4 LICENSE-Brosowsky.md.
.4 LICENSE-Mann.md.
.4 LICENSE-Wheeler.md.
.4 main.js.
.4 music.js.
.4 rhythms.js.
.4 Tone.js.
.4 Tonejs-Instruments.js.
.3 samples.
.4 bass-electric.
.4 bassoon.
.4 cello.
.4 clarinet.
.4 contrabass.
.4 flute.
.4 french-horn.
.4 guitar-acoustic.
.4 guitar-electric.
.4 guitar-nylon.
.4 harmonium.
.4 harp.
.4 organ.
.4 piano.
.4 saxophone.
.4 trombone.
.4 trumpet.
.4 tuba.
.4 violin.
.4 xylophone.
.2 latex.
.3 report.tex.
.3 report.pdf.
.3 references.bib.
.2 index.html.
.2 README.md.
.2 LICENSE.md.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Codebase}

The entire codebase (and the original \code{LaTeX} files for this very report) can be found on Claire's GitHub repository: \href{https://github.com/cgoecknerwald/procedural-soundscape}{github.com/cgoecknerwald/procedural-soundscape}. The web application is live at \href{https://cgoecknerwald.github.io/procedural-soundscape/}{cgoecknerwald.github.io/procedural-soundscape/}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Workflow}

Rather than using \href{https://cloud.google.com/appengine/}{Google App Engine}, or similar, we simply hosted the website for free on Claire's personal GitHub site, \href{https://cgoecknerwald.github.io/procedural-soundscape}{cgoecknerwald.github.io/procedural-soundscape}. This greatly simplified the workflow, as we could easily push HTML/CS/JS to the GitHub repository, and it would then be immediately updated online with no extra work.

\begin{itemize}
	\item \href{https://github.com/cgoecknerwald/procedural-soundscape/commits/master}{Commit history}: one can view the entirety of commits to this project over time.
	\item \href{https://github.com/cgoecknerwald/procedural-soundscape/issues}{Issue tracking}: We kept track of bugs and wishful enhancements with the issue tracker. At this time, we have 5 open issues and 8 closed issues.
	\item \href{https://github.com/cgoecknerwald/procedural-soundscape/projects}{Project management}: We at times used two \href{https://en.wikipedia.org/wiki/Kanban_(development)}{Kanban}-inspired workflow management boards. One board represented primarily the user interface work, and the other represented primarily the sound design work. In general, however, we relied mostly on verbal in-person communication and issue tracking for workflow.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Implementation Issues}

We looked into playing and modifying audiofiles (such as \code{MP3}s or \code{WAV}s) but the integration with Tone.js seemed too complicated \cite{tonejs-issue}. This threw us off track for several weeks as we searched for good synths to use (we found none). Claire had switched to \href{https://duckduckgo.com/}{DuckDuckGo} during the project, which has a much less 'intelligent' search algorithm, which would not return the repo \lightcode{tonejs-instruments} from a search for ``tone js instruments''. Google, however, did, so eventually it was found. In \lightcode{tonejs-instruments}, they use publicly available \code{WAV}s from about a dozen instruments, including saxophone and piano (but no drums) \cite{tonejs-instruments}.  We relied heavily on this repo due to its realistic sound qualities. Originally, we believe that \href{https://github.com/Tonejs/Tone.js/issues/290}{this issue} references why we can't use \code{WAV}-format files in Tone.js. However, that issue seems to be outdated, incorrect, or misread.

We discussed moving instruments synths into \code{assets/js/instruments.js}, out of \code{assets/js/main.js}. Moving roots/scales/chord progressions/rhythms/min \& max on octaves in \code{assets/js/chords.js}. As the music portion of the site grew more and more complicated, the file grew messier and messier, and it became hard to add to and still understand what was happening. Our \code{assets/js/main.js} (UI) and \code{assets/js/music.js} (music generation) files were actually originally one single file, since the UI and the music had to be synced together. This split was one of the first big modularization changes we made. We also took the time to break up \code{assets/js/music.js} into separate functions, to improve readability and comprehension. This modularization had its own problems, in that the functions had to share a lot of data between each other and with the UI. This data sharing problem was eventually solved somewhat satisfactorily through a combination of function static variables, refactoring so fewer functions needed the same data, and exported, effectively-global variables.

We had a variety of other implementation challenges, some of which were touched in the Musical Review section. The bulk of the challenges came from scheduling all the events at the correct time. We wanted to schedule measures one measure ahead of time, for example, to resolve a bug where sometimes the first note of the measure would be dropped. This meant that we needed to include a countdown for the first measure after the user pressed the play button, but more importantly, it required careful work to synchronize the UI. We have a display of the notes that are currently playing, with the current note highlighted. We had to think carefully about where in the code to trigger the updates of the UI, given that what is being displayed is not what was most recently generated. Instead, what is displayed on the UI is what was generated last measure, and what was most recently generated is the next upcoming measure.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Licensing}

As all open-source contributors should be, we were careful to correctly attribute credit (and liability!) to repositories and sources we borrowed from. We relied on one repository, by Github user \code{wheelibin}, that did not have a license. As Github-hosted \href{https://choosealicense.com/}{\textit{Choose A License}}, hosted and run by GitHub, was very helpful in guiding us (and \code{wheelibin}) through the licensing process. Failure to license an open-source project can lead to unsavory legal troubles.

\begin{quote}
When you make a creative work (which includes code), the work is under exclusive copyright by default. Unless you include a license that specifies otherwise, nobody else can copy, distribute, or modify your work without being at risk of take-downs, shake-downs, or litigation. Once the work has other contributors (each a copyright holder), “nobody” starts including you. \\
\dots \\
If you find software that doesn’t have a license, that generally means you have no permission from the creators of the software to use, modify, or share the software. Although a code host such as GitHub may allow you to view and fork the code, this does not imply that you are permitted to use, modify, or share the software for any purpose. \cite{choose-license-none}
\end{quote}


Thankfully, \code{wheelibin} was responsive to \href{https://github.com/wheelibin/synaesthesia/issues/2}{our request} via GitHub's issue tracker to license his repository. He ended up using the MIT license by adding it to his \code{README.md} \cite{synaesthesia-license}. Once he had done so, we were free to use and modify his work, so long as we included the original license along with our distribution.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Analysis & Conclusion %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Analysis \& Conclusion}
\subsection{Original Goals}
\begin{itemize}
	\item Notably, we did not integrate with any live input (but I suspect it would take less than a full day to integrate with the camera, grab some value from the camera (eg: mean pixel color), linearly scope it to a `temperature'-type value, and apply said temperature as a variable to any of our musical-type variables or functions.)
	\item We did not quite achieve the coffeehouse jazz aesthetic, but I believe we could, given more time to experiment.
\end{itemize}

\subsection{Regrets}
\begin{itemize}
	\item Immediately find \lightcode{tonejs-instruments}. We spent a lot of time looking for and trying to create good synthetic instruments. That time could've easily been saved if we had found \lightcode{tonejs-instruments} from the beginning.
	\item Construct a clear, more well-defined end goal. We had many ideas of what we wanted to thought we might want to include in the final product, but didn't precisely define which of these we for sure wanted to include. As a result, we weren't always synced up on what our immediate goals were for the project, which sometimes resulted in wasted effort.
	\item Plan out music generation more carefully from the beginning. We sort of just started trying things out to see if they would work, then building on top of it. As our idea for the project changed, this sometimes required reconsidering the entire structure of how music generation system.
\end{itemize}

In general, we felt that we had taken appropriate steps throughout.

\subsection{Continuation}
\begin{itemize}
	\item Flesh out the soundscape to make it more musical.
	\item Add more instrument lines (e.g. a harmony instrument).
	\item Implement phrasing as best as possible.
	\item More sophisticated repeat mechanisms (for instance, repeating a section, but transposing it up or down a few notes from the original).
	\item Integrate chords and chord progressions.
	\item Allow more parameters to vary from refresh to refresh (for example, changing the random chances of repeats, runs, etc.).
	\item Preload background images to avoid white flashing.
	\item Add more pleasant, fading background image transition.
	\item Fix the saxophone from \lightcode{tonejs-instruments}. Currently, it gets a wispy / airy / reedy tone in the upper ranges, such that you can hear the reed from the instrument. This is probably caused by a high-pitched soundfile that is interpolated to the intermediate pitch range. Ideally, we would remove the soundfile that contains this wispiness, and \lightcode{tonejs-instruments} would successfully extrapolate pitches without it.
	\item Add a music notation system using standard bar notation. This can be done with moderately complex CSS and JS implementation, as demonstrated \href{https://codepen.io/laviperchik/pen/mIACq}{here} on Codepen. \cite{css-musical-notes}
	\item Spend more time trying to get \lightcode{Tone.js}'s \code{MetalSynth} function to work appropriately. At the beginning, we seemed to have a perfectly fine synths for \code{Kick}, \code{HiHat}, \code{OpenHat}, and \code{DampedOpenHat} functionality. However, it either broke due to some yet-unidentified internal conflict (such as a clash between two \lightcode{Tone.js} implementations), or we simply had much better taste in synths by the time we began to use it in our music. Either way, we were not satisfied enough to use the synth.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Contact %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Contact}

Claire Goeckner-Wald (\href{mailto://claire@caltech.edu}{claire@caltech.edu}) or Amy Xiong (\href{mailto://axiong@caltech.edu}{axiong@caltech.edu}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Appendix %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Appendix}

\subsection{Original Proposal}
The original proposal, submitted Monday, 22 October 2018:
\begin{quote}
We aim to build a procedurally-generated soundscape inspired by `\href{https://www.youtube.com/watch?v=K2Q6YO3Ez44}{coffeehouse jazz}'. The ideal end-product is jazz-esque music that can respond in live time to environmental variables. We selected jazz as our target because we believe it will be easier to procedurally generate due to the improvisational and diverse nature of jazz. We will initially follow this \href{http://www.procjam.com/tutorials/en/music/}{Procedural Music Generation tutorial}. To begin, we select a `palette' of frequencies and sounds that function well together. Then, we will add rhythm and beat to generate our base product. After this is accomplished, we may add additional complexities such as palette-changes, instrument modifications, etc. We may additionally attempt to link these complexities to environmental variables for an interactive soundscape.

We will use SuperCollider for the sound synthesis and algorithmic composition. We will begin with \href{http://doc.sccode.org/Classes/MdaPiano.html}{MdaPiano} for a piano synthesizer. We will also add drums, saxophone, bass, and other instruments, as appropriate. Ideally we will have large suite of instrument synthesizers. We have considered creating a web application for this project, a la \href{https://asoftmurmur.com/}{Soft Murmur} and similar websites, which allow the client to modify the mixture directly. If we chose to do this, we might use \href{https://console.cloud.google.com/projectselector/appengine}{Google App Engine}.
\end{quote}

\subsection{MIT License}
The MIT License, in its most frequent form:

\begin{quote}
Copyright (c) $\langle$year$\rangle$ $\langle$copyright holders$\rangle$

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE. \cite{mit-license}
\end{quote}

\subsection{The GNU General Public License v3.0}
The GNU GPL v3, in its most frequent form (notably, the full text of the license is online):

\begin{quote}
$\langle$one line to give the program's name and a brief idea of what it does.$\rangle$
Copyright (C) $\langle$year$\rangle$  $\langle$name of author$\rangle$

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see $\langle$https://www.gnu.org/licenses/$\rangle$. \cite{gplv3}
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%% References section: %%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliography{references}
\bibliographystyle{plain}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% End of document %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

